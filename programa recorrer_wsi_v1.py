# -*- coding: utf-8 -*-
"""Recorrer WSI completo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BQZXNOFU3ADVTVM46i1yugqHw9alXvqD
"""

# Conectar con Google Drivee()
from google.colab import drive
drive.mount('/content/drive')
base_folder = "/content/drive/MyDrive/00 VIU/10 TFM"
# importar credenciales de Hugging face
from google.colab import userdata
import os
from huggingface_hub import login

hf_token = userdata.get('HF_TOKEN')

# instalar las librerías
!pip install -q datasets evaluate keras_cv
!pip install --upgrade transformers
!pip install -q tensorflow
!pip install -q tf-keras

!pip install openslide-python
!pip install openslide-bin
!apt-get install openslide-tools
import os
if not os.environ.get('LD_LIBRARY_PATH'):
    os.environ['LD_LIBRARY_PATH'] = ''
os.environ['LD_LIBRARY_PATH'] += ':/usr/local/lib'

import openslide
import matplotlib.pyplot as plt
import pickle
import transformers
import evaluate
from transformers import AutoModelForImageClassification, AutoImageProcessor,TrainingArguments, Trainer
import numpy as np

from PIL import Image as PILImage
import torch

# VALIDAR SI SE CUENTA CON GPU PARA OPTIMIZAR EJECUCION
if torch.cuda.is_available():
    device = torch.device("cuda")
    print(f"GPU disponible: {torch.cuda.get_device_name(0)}")
else:
    device = torch.device("cpu")
    print("No hay GPU disponible, usando CPU.")

# CARGAR EL MODELO DE CLASIFICACION DE PARCHES

model_path=base_folder+"/Modelos entrenados/Swin Base v1 230625"

# Cargar el image_processor:
image_processor = AutoImageProcessor.from_pretrained(model_path)
print("image processor cargado ok")
# Cargar el modelo
num_labels = 2
model = AutoModelForImageClassification.from_pretrained(
    model_path,
    num_labels=num_labels,
    ignore_mismatched_sizes = True
)
print("modelo cargado ok")

# Mover el modelo a la GPU:
model.to(device)

# CARGAR UN WSI
ruta_wsi=base_folder+"/Datasets/CAMELYON16/images/patient_002_node_0.tif"

# INICIALIZAR VARIABLES
patch_num,fila,col,cant_in_batch=0,0,0,0
lista_imgs,heatmap,list_filas,list_columnas,list_parches=[],[],[],[],[]
status=""

# Commented out IPython magic to ensure Python compatibility.
# # BUCLE PARA RECORRER EL WSI

try:
    with openslide.OpenSlide(ruta_wsi) as slide:
        print(f"Archivo ok. Dimensiones del nivel 0: {slide.level_dimensions[0]}")
        # Leer un tile específico del nivel más bajo
        WSI_h=slide.level_dimensions[0][1]
        WSI_w=slide.level_dimensions[0][0]
        batch_p,p_size, haya_filas,haya_columnas,listado=32,224,True,True,[]


        while haya_filas:
          while haya_columnas:
            img = slide.read_region((col, fila), 1, (p_size, p_size))
            lista_imgs = lista_imgs+[img.convert('RGB')]
            list_filas.append(fila)
            list_columnas.append(col)
            list_parches.append(patch_num)
            cant_in_batch += 1

            if cant_in_batch == batch_p:
              # print(f"lote finalizado {patch_num//batch_p}; patch num: {patch_num}")
              inputs = image_processor(images=lista_imgs, return_tensors="pt")

              # Mover los inputs a la GPU:
              inputs = {k: v.to(device) for k, v in inputs.items()}

              model.eval() # Poner el modelo en modo de evaluación
              with torch.no_grad(): # Desactivar el cálculo de gradientes
                outputs = model(pixel_values=inputs['pixel_values'])
                logits = outputs.logits
                probs = torch.softmax(logits, dim=-1)
                listado = [float(probs[i,1]) for i in range(probs.shape[0])]
                heatmap = heatmap + listado
              lista_imgs = []
              cant_in_batch = 0
            else:
              pass
            patch_num += 1
            col += (p_size*2)
            haya_columnas = (col+p_size*2 <= WSI_w)



          fila += (p_size*2)
          col = 0
          haya_columnas = True
          haya_filas = (fila <= WSI_h)



          if fila%448 == 0 and (fila//448)%20 ==0:
            print(f"Porcentaje de avance: {fila/WSI_h:.0%}")


        status = "ok"

except openslide.OpenSlideError as e:
    print(f"Error al abrir el WSI: {e}")
except FileNotFoundError:
    print(f"Archivo no encontrado: {ruta_wsi}")


# Guardar las variables en archivo:
if status == "ok":
 variables={'WSI_h':WSI_h,
           'WSI_w':WSI_w,
            'patch_num':patch_num,
            'fila':fila,
            'col':col,
            'cant_in_batch':cant_in_batch,
            'lista_imgs':lista_imgs,
            'heatmap':heatmap,
            'list_filas':list_filas,
            'list_columnas':list_columnas,
            'list_parches':list_parches
          }
 path_variables= base_folder+"/TFM Notebooks/Dumps de variables y objetos/variables WSI.pkl"
 with open(path_variables, 'wb') as archivo:
          pickle.dump(variables, archivo)

 p_max_ancho= WSI_w//(p_size*2)
 print("parches por fila: ",p_max_ancho)
 heatmap2=[]

 if len(heatmap)%p_max_ancho !=0:
   ult=((len(heatmap)//p_max_ancho)+1)*p_max_ancho - len(heatmap)
   list_append=[0]*ult
   heatmap2=heatmap+list_append
 else:
  heatmap2=heatmap
 heatmapc = [1-x for x in heatmap2]
 heatmap_np=np.array(heatmapc).reshape(len(heatmapc)//p_max_ancho,p_max_ancho)
 print("tamaño heatmap_np: ",heatmap_np.shape)

 # VISUALIZAR EL MAPA DE CALOR
 fig, ax = plt.subplots(figsize=(6, 5))
 im=ax.imshow(heatmap_np,cmap='RdYlGn',interpolation='nearest',origin="upper",vmin=0,vmax=1)
 ax.xaxis.tick_top() # Mueve los ticks del eje X a la parte superior
 ax.xaxis.set_label_position('top') # Mueve la etiqueta del eje X a la parte superior

 fig.colorbar(im,label="Valor de la celda")
 plt.savefig(base_folder+"/TFM Notebooks/Dumps de variables y objetos/heatmap.png",dpi=1200)
 plt.show()

 # VISUALIZAR LA IMAGEN DEL WSI
 with openslide.OpenSlide(ruta_wsi) as slide:
        thumb = slide.read_region((0,0), 8,slide.level_dimensions[8] )
 fig, ax = plt.subplots(figsize=(6, 5))
 im=ax.imshow(thumb)
 # plt.savefig(base_folder+"/TFM Notebooks/Dumps de variables y objetos/heatmap.png",dpi=1200)
 plt.show()

 # VISUALIZAR LOS BUCKETS DE DISTRIBUCION DE PROBABILIDADES
 data = np.array(heatmap)
 bins = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]
 counts, _ = np.histogram(data, bins=bins)
 print("\nRangos (bins):", bins)
 print("Conteo de datos en cada rango:", counts)
 plt.bar(bins[0:5],counts,width=0.1)
 plt.xlabel=bins[0:5]

