# -*- coding: utf-8 -*-
"""VGG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c9CrbcJMAy-AVPi481EdFtKr9o7Fp24J

MODELO PRE ENTRENADO VGG - FINE TUNING PCAM
Dataset: Patch Camelyon
Fuente del modelo: keras_hub
Modelo: VGG19 preentreenada Imagenet
Entorno de los modelos: Keras Hub, tensorflow datasets
"""

# Conectar con Google Drive
from google.colab import drive
_ = drive.mount('/content/drive')
base_folder = "/content/drive/MyDrive/00 VIU/10 TFM"

!pip install tensorflow --upgrade
!pip install keras_cv
!pip install keras_hub

import tensorflow as tf
import keras
import keras_hub
import numpy as np
import matplotlib.pyplot as plt

# Leer datasets PCam desde copia en disco:
ruta_pcam_tr = base_folder+"/Datasets/pcamelyon_tf/TFcamelyon_train"
train_ds = tf.data.Dataset.load(ruta_pcam_tr)
ruta_pcam_val = base_folder+"/Datasets/pcamelyon_tf/TFcamelyon_val"
val_ds = tf.data.Dataset.load(ruta_pcam_val)

# Usar la función 'map' para dejar solamente la imagen y la etiqueta
# quitando la identificación de la imagen
train_ds = train_ds.map(lambda x: (x["image"], x["label"]), \
                        num_parallel_calls=tf.data.AUTOTUNE)
val_ds = val_ds.map(lambda x: (x["image"], x["label"]), \
                        num_parallel_calls=tf.data.AUTOTUNE)

print("len(train_ds):",len(train_ds))
print("len(val_ds):",len(val_ds))

#  Instancier el preprocesador de entrada para normalizar las imagenes al rango 0..1
preprocessor = keras.layers.Pipeline([keras.layers.Rescaling(1.0 / 255)])
# Preparar el dataset en lotes y usar prefetch para optimizar el entrenamiento
batch_size = 32
train_ds = train_ds.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_ds.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)

# Instanciar el clasificador de imagenes basado en resnet
# model = keras_hub.models.VGGBackbone.from_preset("vgg_19_imagenet")
image_classifier = keras_hub.models.ImageClassifier.from_preset(
    "vgg_19_imagenet",
    activation="softmax",
    num_classes=2,
    preprocessor=preprocessor,
)
# Compilar el modelo:
image_classifier.compile(
    optimizer=keras.optimizers.Adam(1e-4),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)

# Entrenar 3 epocas
image_classifier.fit(
    train_ds,
    validation_data=val_ds,
    epochs=3,
  )

# Cargar el dataset de prueba
ruta_pcam_test = base_folder+"/Datasets/pcamelyon_tf/TFcamelyon_test"
test_ds = tf.data.Dataset.load(ruta_pcam_test)
# Usar la función 'map' para dejar solamente la imagen y la etiqueta
# quitando la identificación de la imagen
test_ds = test_ds.map(lambda x: (x["image"], x["label"]), \
                        num_parallel_calls=tf.data.AUTOTUNE)
print("len(test_ds):",len(test_ds))
# Preparar el dataset en lotes y usar prefetch para optimizar la evaluación
test_ds = test_ds.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)
# Evaluar el modelo
_, accuracy = image_classifier.evaluate(test_ds)
print(f"Accuracy en el dataset de prueba: {accuracy}")

image_classifier.save_to_preset(base_folder+"/Modelos entrenados/VGG19v1")